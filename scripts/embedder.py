# scripts/embedder.py

import os
import pdfplumber
import chromadb
from sentence_transformers import SentenceTransformer
from uuid import uuid4

# ðŸ”§ Configuration
DATA_DIR = "data"
EMBED_DIR = "embeddings"
CHROMA_DIR = os.path.join(EMBED_DIR, "chroma")
os.makedirs(CHROMA_DIR, exist_ok=True)

# ðŸ“Œ Load embedding model
print("ðŸ”  Loading embedding model...")
embedder = SentenceTransformer("all-MiniLM-L6-v2")

# ðŸ§  Connect to ChromaDB (new syntax)
print("ðŸ“¦ Connecting to ChromaDB...")
client = chromadb.PersistentClient(path=CHROMA_DIR)
collection = client.get_or_create_collection(name="documents")

# ðŸ“‚ Read and embed PDFs
def process_pdf(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        full_text = ""
        for page in pdf.pages:
            full_text += page.extract_text() or ""
    return full_text

def chunk_text(text, chunk_size=700, overlap=150):
    words = text.split()
    chunks = []
    i = 0
    while i < len(words):
        chunk = words[i:i+chunk_size]
        chunks.append(" ".join(chunk))
        i += chunk_size - overlap
    return chunks

print("ðŸ“„ Reading PDFs from /data...")
for file in os.listdir(DATA_DIR):
    if file.endswith(".pdf"):
        filepath = os.path.join(DATA_DIR, file)
        print(f"ðŸ“˜ Processing: {file}")
        raw_text = process_pdf(filepath)
        chunks = chunk_text(raw_text)

        embeddings = embedder.encode(chunks).tolist()
        ids = [str(uuid4()) for _ in chunks]

        collection.add(
            documents=chunks,
            embeddings=embeddings,
            ids=ids,
            metadatas=[{"source": file}] * len(chunks)
        )

# ðŸ’¾ Persist DB
print("ðŸ’¾ Saving DB...")
print("âœ… Embedding and storage complete.")
